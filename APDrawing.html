
<html>
<head>
    <title>APDrawing Generation</title>
    <meta HTTP-EQUIV="Content-Type" CONTENT="text/html;charset=UTF-8">
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
      MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
      //MathJax.Hub.Config({"HTML-CSS": { scale: 80}});
    </script>
    <script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body>
    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;">Multi-style and Cross-modal Deep Generation Models for Artistic Portrait Drawings</p></center>
    <hr>
    <p>
    <font size=+1><b>Overview</b></font><br>
    This open-source project aims at generating <strong>Artistic Portrait line Drawing (APDrawing)</strong>, which is more challenging than other kinds of artistic image generation because of <strong>high abstraction and high semantic constraints</strong>. This project studies the problem of automatic artistic portrait drawing generation, and achieves single-style, multi-style artistic portrait drawing generation and cross-modal artistic talking portrait drawing video generation. 
    <a target="_blank" href="images/multi.jpeg"><img src="images/multi.jpeg" width="800"></a><br>
    </p>
    </hr>
    <hr>
    <p>
    <font size=+1><b>Publications</b></font><br>
    <ol>
        <li>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs. <br>
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR Oral). 2019: 10743-10752. <br>
            <a href="#APDrawingGAN">[Details]</a>
            <a href="https://github.com/yiranran/APDrawingGAN">[Github Code]</a>
        </li>
        <li>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping. <br>
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020: 8217-8225. <br>
            <a href="#UPD">[Details]</a>
            <a href="https://github.com/yiranran/Unpaired-Portrait-Drawing">[Github Code]</a>
        </li>
        <li>
            Yi R, Xia M, Liu Y J, Lai Y K, Rosin P L. <br>
            Line Drawings for Face Portraits From Photos Using Global and Local Structure Based GANs. <br>
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021, 43(10): 3462-3475. <br>
            <a href="#APDrawingGAN2">[Details]</a>
            <a href="https://github.com/yiranran/APDrawingGAN2">[Github Code]</a>
        </li>
        <li>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data. <br>
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022. DOI 10.1109/TPAMI.2022.3147570. <br>
            <a href="#QMUPD">[Details]</a>
            <a href="https://github.com/yiranran/QMUPD">[Github Code]</a>
        </li>
        <li>
            Yi R, Ye Z, Fan R, Shu Y, Liu Y J, Lai Y K, Rosin P L. <br>
            Animating Portrait Line Drawings from a Single Face Photo and a Speech Signal. <br>
            Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings (SIGGRAPH ’22 Conference Proceedings), 2022. DOI 10.1145/3528233.3530720.  <br>
            <a href="#AnimatePortrait">[Details]</a>
            <a href="https://github.com/AnimatePortrait/AnimatePortrait">[Github Code]</a>
        </li>
    </ol>
    </p>
    <hr>


    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;">
            <a name="APDrawingGAN" id="APDrawingGAN"></a>APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs</p></center>
    <center>
        <table style="text-align: center">
            <tr>
                <td>
                    &nbsp<a target="_blank" href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yong-Jin Liu</a><sup>1</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="http://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a><sup>2</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://users.cs.cf.ac.uk/Paul.Rosin/">Paul L. Rosin</a><sup>2</sup>&nbsp
                </td>
            </tr>
            <tr>
                <td colspan="2">
                    <sup>1</sup> Tsinghua University
                </td>
                <td colspan="2">
                    <sup>2</sup> Cardiff University
                </td>
            </tr>
            <tr>
                <td colspan="4">
                <strong><font size=+1>Published in CVPR 2019 (Oral)</font></strong>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <div>
        <a target="_blank" href="images/CVPR-2019-APDrawingGAN.jpg"><img src="images/CVPR-2019-APDrawingGAN.jpg" width="800"></a><br>
        <p>
        <font size=-1>Figure: (a) An artist draws a portrait drawing using a sparse set of lines and very few shaded regions to capture the distinctive appearance of a given face photo. (b) Our APDrawingGAN learns this artistic drawing style and automatically transforms a face photo into a high-quality artistic portrait drawing. (c) Using the same input face photo, six state-of-the-art style transfer methods cannot generate desired artistic drawings: Deep Image Analogy, CNNMRF, Gatys and Headshot Portrait change facial features or fail to capture style, CycleGAN and Pix2Pix produce false details around hair, eyes or corners of the mouth.</font>
        </p>
    </div>

    <hr>
    <p>
    <font size=+1><b>Abstract</b></font><br>
    <p>
    Significant progress has been made with image stylization using deep learning, especially with generative adversarial networks (GANs). However, existing methods fail to produce high quality artistic portrait drawings. Such drawings have a highly abstract style, containing a sparse set of continuous graphical elements such as lines, and so small artifacts are more exposed than for painting styles. Moreover, artists tend to use different strategies to draw different facial features and the lines drawn are only loosely related to obvious image features. To address these challenges, we propose APDrawingGAN, a novel GAN based architecture that builds upon hierarchical generators and discriminators combining both a global network (for images as a whole) and local networks (for individual facial regions). This allows dedicated drawing strategies to be learned for different facial features. Since artists’ drawings may not have lines perfectly aligned with image features, we develop a novel loss to measure similarity between generated and artists’ drawings based on distance transforms, leading to improved strokes in portrait drawing. To train APDrawingGAN, we construct an artistic drawing dataset containing high-resolution portrait photos and corresponding professional artistic drawings. Extensive experiments, and a user study, show that APDrawingGAN produces significantly better artistic drawings than state-of-the-art methods.
    </p>

    <hr>
    <table>
        <tr>
            <td><a target="_blank" href="images/cvpr2019_APDrawingGAN_firstpage.jpg"><img src="images/cvpr2019_APDrawingGAN_firstpage.jpg" width="200"></a></td>
            <td>
                <div><font size=+1><b>Paper</b></font></div>
                <div><a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.pdf">APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs</a><br><br></div>

                <div><font size=+1><b>Supplmental Material</b></font></div>
                <div><a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Yi_APDrawingGAN_Generating_Artistic_CVPR_2019_supplemental.pdf">Supplemental Material</a><br><br></div>

                <div><font size=+1><b>Github Code</b></font></div>
                <div><a target="_blank" href="https://github.com/yiranran/APDrawingGAN"/>APDrawingGAN</a>, <a target="_blank" href="https://github.com/yiranran/APDrawingGAN-Jittor"/>APDrawingGAN-Jittor</a><br><br></div>
            </td>
        </tr>
    </table>

    <hr>
    <p>
    <font size=+1><b>Publication</b></font><br>
        <p>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs. <br>
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR Oral). 2019: 10743-10752. <br>
        <a href="https://dblp.uni-trier.de/rec/conf/cvpr/YiLLR19.html?view=bibtex">BibTeX</a>
        </p>
    </p>
    <hr>



    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;">
            <a name="UPD" id="UPD"></a>Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping</p></center>
    <center>
        <table style="text-align: center">
            <tr>
                <td>
                    &nbsp<a target="_blank" href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yong-Jin Liu</a><sup>1</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="http://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a><sup>2</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://users.cs.cf.ac.uk/Paul.Rosin/">Paul L. Rosin</a><sup>2</sup>&nbsp
                </td>
            </tr>
            <tr>
                <td colspan="2">
                    <sup>1</sup> Tsinghua University
                </td>
                <td colspan="2">
                    <sup>2</sup> Cardiff University
                </td>
            </tr>
            <tr>
                <td colspan="4">
                <strong><font size=+1>Published in CVPR 2020</font></strong>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <div>
        <a target="_blank" href="images/CVPR-2020-Unpaired.jpg"><img src="images/CVPR-2020-Unpaired.jpg" width="800"></a><br>
        <p>
        <font size=-1>Figure: Comparison with state-of-the-art methods: (a) input face photo; (b)-(c) style transfer methods: Gatys and Linear Style Transfer; (f)-(h) single-modal image-to-image translation methods: DualGAN, CycleGAN, UNIT; (d)-(e) multi-modal image-to-image translation methods MUNIT and ComboGAN; (i) a portrait generation method APDrawingGAN; (j) our method.</font>
        </p>
    </div>

    <hr>
    <p>
    <font size=+1><b>Abstract</b></font><br>
    <p>
    Portrait drawing is a common form of art with high abstraction and expressiveness. Due to its unique characteristics, existing methods achieve decent results only with paired training data, which is costly and time-consuming to obtain. In this paper, we address the problem of automatic transfer from face photos to portrait drawings with unpaired training data. We observe that due to the significant imbalance of information richness between photos and drawings, existing unpaired transfer methods such as CycleGAN tend to embed invisible reconstruction information indiscriminately in the whole drawings, leading to important facial features partially missing in drawings. To address this problem, we propose a novel asymmetric cycle mapping that enforces the reconstruction information to be visible (by a truncation loss) and only embedded in selective facial regions (by a relaxed forward cycle-consistency loss). Along with localized discriminators for the eyes, nose and lips, our method well preserves all important facial features in the generated portrait drawings. By introducing a style classifier and taking the style vector into account, our method can learn to generate portrait drawings in multiple styles using a single network. Extensive experiments show that our model outperforms state-of-the-art methods.
    </p>

    <hr>
    <table>
        <tr>
            <td><a target="_blank" href="images/cvpr2020_UPD_firstpage.jpg"><img src="images/cvpr2020_UPD_firstpage.jpg" width="200"></a></td>
            <td>
                <div><font size=+1><b>Paper</b></font></div>
                <div><a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yi_Unpaired_Portrait_Drawing_Generation_via_Asymmetric_Cycle_Mapping_CVPR_2020_paper.pdf">Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping</a><br><br></div>

                <div><font size=+1><b>Supplmental Material</b></font></div>
                <div><a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yi_Unpaired_Portrait_Drawing_CVPR_2020_supplemental.pdf">Supplemental Material</a><br><br></div>

                <div><font size=+1><b>Github Code</b></font></div>
                <div><a target="_blank" href="https://github.com/yiranran/Unpaired-Portrait-Drawing"/>Unpaired-Portrait-Drawing</a>, <a target="_blank" href="https://github.com/yiranran/Unpaired-Portrait-Drawing-Jittor"/>Unpaired-Portrait-Drawing-Jittor</a><br><br></div>

                <div><font size=+1><b>Demo</b></font></div>
                <div><a target="_blank" href="https://colab.research.google.com/drive/1U1fPXD1JukuKPOrhGMX1iaJC-d8_RUYr"/>
                Google Colab</a></div>
            </td>
        </tr>
    </table>

    <hr>
    <p>
    <font size=+1><b>Publication</b></font><br>
        <p>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping. <br>
            IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2020: 8217-8225. <br>
        <a href="https://dblp.uni-trier.de/rec/conf/cvpr/YiLLR20.html?view=bibtex">BibTeX</a>
        </p>
    </p>
    <hr>


    

    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;"><a name="APDrawingGAN2" id="APDrawingGAN2"></a>Line Drawings for Face Portraits From Photos Using Global and Local Structure Based GANs</p></center>
    <center>
        <table style="text-align: center">
            <tr>
                <td>
                    &nbsp<a target="_blank" href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://scholar.google.com/citations?user=Wr2Ve9MAAAAJ&hl=en&oi=ao">Mengfei Xia</a><sup>1</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yong-Jin Liu</a><sup>1</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="http://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a><sup>2</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://users.cs.cf.ac.uk/Paul.Rosin/">Paul L. Rosin</a><sup>2</sup>&nbsp
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <sup>1</sup> Tsinghua University
                </td>
                <td colspan="2">
                    <sup>2</sup> Cardiff University
                </td>
            </tr>
            <tr>
                <td colspan="5">
                <strong><font size=+1>Published in TPAMI 2021</font></strong>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <div>
        <a target="_blank" href="images/TPAMI-2020-portrait.jpg"><img src="images/TPAMI-2020-portrait.jpg" width="800"></a><br>
        <p>
        <font size=-1>Figure: (a) An artist draws a portrait drawing using a sparse set of lines and very few shaded regions to capture the distinctive appearance of a person or a given face photo. (b) Our APDrawingGAN++ learns this artistic drawing style and automatically transforms a face photo into a high-quality artistic portrait drawing. (c) Using the same input face photo, six state-of-the-art style transfer methods cannot generate desired artistic drawings. The drawings output by Deep Image Analogy, CNNMRF and Gatys seem not to obtain the right style and have some facial features changed, which makes them difficult to recognize. CycleGAN and Pix2Pix produce false details around hairs, eyes or corners of the lip. APDrawingGAN works relatively well, but produces less delicate facial features (e.g., more messy lips) and hair than our result.</font>
        </p>
    </div>

    <hr>
    <p>
    <font size=+1><b>Abstract</b></font><br>
    <p>
    Despite significant effort and notable success of neural style transfer, it remains challenging for highly abstract styles, in particular line drawings. In this paper, we propose APDrawingGAN++, a generative adversarial network (GAN) for transforming face photos to artistic portrait drawings (APDrawings), which addresses substantial challenges including highly abstract style, different drawing techniques for different facial features, and high perceptual sensitivity to artifacts. To address these, we propose a composite GAN architecture that consists of local networks (to learn effective representations for specific facial features) and a global network (to capture the overall content). We provide a theoretical explanation for the necessity of this composite GAN structure by proving that any GAN with a single generator cannot generate artistic styles like APDrawings. We further introduce a classification-and-synthesis approach for lips and hair where different drawing styles are used by artists, which applies suitable styles for a given input. To capture the highly abstract art form inherent in APDrawings, we address two challenging operations: (1) coping with lines with small misalignments while penalizing large discrepancy and (2) generating more continuous lines-by introducing two novel loss terms: one is a novel distance transform loss with nonlinear mapping and the other is a novel line continuity loss, both of which improve the line quality. We also develop dedicated data augmentation and pre-training to further improve results. Extensive experiments, including a user study, show that our method outperforms state-of-the-art methods, both qualitatively and quantitatively.
    </p>

    <hr>
    <table>
        <tr>
            <td><a target="_blank" href="images/tpami2021_APDrawingGAN2_firstpage.jpg"><img src="images/tpami2021_APDrawingGAN2_firstpage.jpg" width="200"></a></td>
            <td>
                <div><font size=+1><b>Paper</b></font></div>
                <div><a target="_blank" href="https://ieeexplore.ieee.org/document/9069416">Line Drawings for Face Portraits From Photos Using Global and Local Structure Based GANs</a><br><br></div>

                <div><font size=+1><b>Supplmental Material</b></font></div>
                <div><a target="_blank" href="https://ieeexplore.ieee.org/document/9069416/media#media">Appendix</a><br><br></div>

                <div><font size=+1><b>Github Code</b></font></div>
                <div><a target="_blank" href="https://github.com/yiranran/APDrawingGAN2"/>APDrawingGAN2</a>, <a target="_blank" href="https://github.com/yiranran/APDrawingGAN2-Jittor"/>APDrawingGAN2-Jittor</a><br><br></div>
            </td>
        </tr>
    </table>

    <hr>
    <p>
    <font size=+1><b>Publication</b></font><br>
        <p>
            Yi R, Xia M, Liu Y J, Lai Y K, Rosin P L. <br>
            Line Drawings for Face Portraits From Photos Using Global and Local Structure Based GANs. <br>
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021, 43(10): 3462-3475. <br>
        <a href="https://dblp.uni-trier.de/rec/journals/pami/YiXLLR21.html?view=bibtex">BibTeX</a>
        </p>
    </p>
    <hr>




    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;"><a name="QMUPD" id="QMUPD"></a>Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data</p></center>
    <center>
        <table style="text-align: center">
            <tr>
                <td>
                    &nbsp<a target="_blank" href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yong-Jin Liu</a><sup>1</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="http://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a><sup>2</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://users.cs.cf.ac.uk/Paul.Rosin/">Paul L. Rosin</a><sup>2</sup>&nbsp
                </td>
            </tr>
            <tr>
                <td colspan="2">
                    <sup>1</sup> Tsinghua University
                </td>
                <td colspan="2">
                    <sup>2</sup> Cardiff University
                </td>
            </tr>
            <tr>
                <td colspan="4">
                <strong><font size=+1>Published in TPAMI 2022</font></strong>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <div>
        <a target="_blank" href="images/TPAMI2022-QMUPD.jpg"><img src="images/TPAMI2022-QMUPD.jpg" width="800"></a><br>
        <p>
        <font size=-1>Figure: Comparison with state-of-the-art methods: (a) input face photo; (b)-(c) style transfer methods: Gatys and Linear Style Transfer; (f)-(h) single-modal image-to-image translation methods: DualGAN, CycleGAN, UNIT; (d) multi-modal image-to-image translation methods MUNIT; (e) our previous conference version (Ours-pre) that outputs three styles; (i) a portrait generation method APDrawingGAN++ using paired training data; (j) our method.</font>
        </p>
    </div>

    <hr>
    <p>
    <font size=+1><b>Abstract</b></font><br>
    <p>
    Face portrait line drawing is a unique style of art which is highly abstract and expressive. However, due to its high semantic constraints, many existing methods learn to generate portrait drawings using paired training data. In this paper, we propose a novel method to automatically transform face photos to portrait drawings using unpaired training data. Our method can (1) learn to generate high quality portrait drawings in multiple styles using a single network and (2) generate portrait drawings in a "new style" unseen in the training data. We observe that existing unpaired translation methods (such as CycleGAN) tend to embed invisible reconstruction information indiscriminately in the whole drawings due to significant information imbalance between the photo and portrait drawing domains, which leads to important facial features missing. To address this problem, we propose a novel asymmetric cycle mapping that enforces the reconstruction information to be visible and only embedded in selective facial regions. Along with localized discriminators for important facial regions, our method well preserves all important facial features. Generator dissection further explains that our model learns to incorporate face semantic information during drawing generation. Extensive experiments including a user study show that our model outperforms state-of-the-art methods.
    </p>

    <hr>
    <table>
        <tr>
            <td><a target="_blank" href="images/tpami2022_QMUPD_firstpage.jpg"><img src="images/tpami2022_QMUPD_firstpage.jpg" width="200"></a></td>
            <td>
                <div><font size=+1><b>Paper</b></font></div>
                <div><a target="_blank" href="https://ieeexplore.ieee.org/document/9699090">Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data</a><br><br></div>

                <div><font size=+1><b>Supplmental Material</b></font></div>
                <div><a target="_blank" href="https://ieeexplore.ieee.org/document/9699090/media#media">Appendix</a><br><br></div>

                <div><font size=+1><b>Github Code</b></font></div>
                <div><a target="_blank" href="https://github.com/yiranran/QMUPD"/>QMUPD</a><br><br></div>
            </td>
        </tr>
    </table>

    <hr>
    <p>
    <font size=+1><b>Publication</b></font><br>
        <p>
            Yi R, Liu Y J, Lai Y K, Rosin P L. <br>
            Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data. <br>
            IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023, 45(1): 905-918. <br>
        <a href="https://dblp.org/rec/journals/pami/YiLLR23.html?view=bibtex">BibTeX</a>
        </p>
    </p>
    <hr>




    <div style="margin-left:auto; margin-right:auto; width:800">
        <center><p style="font-size:23px; font-weight: bold;"><a name="AnimatePortrait" id="AnimatePortrait"></a>Animating Portrait Line Drawings from a Single Face Photo and a Speech Signal</p></center>
    <center>
        <table style="text-align: center">
            <tr>
                <td>
                    &nbsp<a target="_blank" href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://qq775193759.github.io/">Zipeng Ye</a><sup>2</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="">Ruoyu Fan</a><sup>2</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://scholar.google.com/citations?hl=en&user=ItEyqMAAAAAJ">Yezhi Shu</a><sup>2</sup>&nbsp
                </td>
                <td>                    
                    &nbsp<a target="_blank" href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Yong-Jin Liu</a><sup>2</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="http://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a><sup>3</sup>&nbsp
                </td>
                <td>
                    &nbsp<a target="_blank" href="https://users.cs.cf.ac.uk/Paul.Rosin/">Paul L. Rosin</a><sup>3</sup>&nbsp
                </td>
            </tr>
            <tr>
                <td colspan="2">
                    <sup>1</sup> Shanghai Jiao Tong University
                </td>
                <td colspan="3">
                    <sup>2</sup> Tsinghua University
                </td>
                <td colspan="2">
                    <sup>3</sup> Cardiff University
                </td>
            </tr>
            <tr>
                <td colspan="7">
                <strong><font size=+1>Published in SIGGRAPH 2022</font></strong>
                </td>
            </tr>
        </table>
    </center>
    <br>

    <div>
        <a target="_blank" href="images/SIG2022.jpg"><img src="images/SIG2022.jpg" width="800"></a><br>
        <p>
        <font size=-1>Figure: Our method generates an artistic animation of a face portrait from a single face photo and a speech signal. In addition to line drawings, our method can be easily applied to portrait cartoon. The input image by SKV Florbal (Public Domain).</font>
        </p>
    </div>

    <hr>
    <p>
    <font size=+1><b>Abstract</b></font><br>
    <p>
    Animating a single face photo is an important research topic which receives considerable attention in computer vision and graphics. Yet line drawings for face portraits, which is a longstanding and popular art form, have not been explored much in this area. Simply concatenating a realistic talking face video generation model with a photo-to-drawing style transfer module suffers from severe inter-frame discontinuity issues. To address this new challenge, we propose a novel framework to generate artistic talking portrait-line-drawing video, given a single face photo and a speech signal. After predicting facial landmark movements from the input speech signal, we propose a novel GAN model to simultaneously handle domain transfer (from photo to drawing) and facial geometry change (according to the predicted facial landmarks). To address the inter-frame discontinuity issues, we propose two novel temporal coherence losses: one based on warping and the other based on a temporal coherence discriminator. Experiments show that our model produces high quality artistic talking portrait-line-drawing videos and outperforms baseline methods. We also show our method can be easily extended to other artistic styles and generate good results. The source Github Code is available at https://github.com/AnimatePortrait/AnimatePortrait .
    </p>

    <hr>
    <table>
        <tr>
            <td><a target="_blank" href="images/siggraph2022_firstpage.jpg"><img src="images/siggraph2022_firstpage.jpg" width="200"></a></td>
            <td>
                <div><font size=+1><b>Paper</b></font></div>
                <div><a target="_blank" href="https://dl.acm.org/doi/10.1145/3528233.3530720">Animating Portrait Line Drawings from a Single Face Photo and a Speech Signal</a><br><br></div>

                <div><font size=+1><b>Supplmental Material</b></font></div>
                <div><a target="_blank" href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3528233.3530720&file=appendix.pdf">Appendix</a><br><br></div>

                <div><font size=+1><b>Github Code</b></font></div>
                <div><a target="_blank" href="https://github.com/AnimatePortrait/AnimatePortrait"/>AnimatePortrait</a><br><br></div>
            </td>
        </tr>
    </table>

    <hr>
    <font size=+1><b>Introduction Video</b></font><br>
    <a href="diffvg.mp4">
    <video width="800px" controls>
        <source src="images/SIG2022_demo.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    </a>

    <hr>
    <p>
    <font size=+1><b>Publication</b></font><br>
        <p>
            Yi R, Ye Z, Fan R, Shu Y, Liu Y J, Lai Y K, Rosin P L. <br>
            Animating Portrait Line Drawings from a Single Face Photo and a Speech Signal. <br>
            Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings (SIGGRAPH ’22 Conference Proceedings), 2022. DOI 10.1145/3528233.3530720.  <br>
        <a href="https://dblp.uni-trier.de/rec/conf/siggraph/YiYFSLLR22.html?view=bibtex">BibTeX</a>
        </p>
    </p>
    <hr>
</body>
</html>
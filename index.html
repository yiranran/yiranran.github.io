
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="description" content="Ran&#39;s home page">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Ran Yi</title>
</head>


<body>

<div style="margin-top:25px">

<table>
	<tr>
		<td width="80%"> 
			<p>
				<font size="5"><strong>Ran Yi &nbsp; (易冉)</strong></font><br><br>

				上海交通大学计算机系 助理教授<br>
				Assistant Professor, Department of Computer Science and Engineering<br>
				Shanghai Jiao Tong University (SJTU), Shanghai, China<br>
				E-mail: ranyi@sjtu.edu.cn<br>
				Office: SEIEE 3-533, SJTU<br>
				<a href="https://scholar.google.com/citations?user=y68DLo4AAAAJ&amp;hl=en" target="_blank">[Google Scholar]</u></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="https://dmcv.sjtu.edu.cn/people/">[DMCV Lab]</a>&nbsp;
			</p>
		</td>
		<td>
			<img src="./files/ry-2.JPG" border="0" width="150">
		</td>
	</tr>
</table>

<h2>Biography &nbsp;   </h2>
<p>
	Ran Yi is an Assistant Professor with Department of Computer Science and Engineering, Shanghai Jiao Tong University, China. She is a member of Digital Media and Computer Vision Laboratory, working closely with <a href="https://dmcv.sjtu.edu.cn/people/">Prof. Lizhuang Ma</a>.
	She received her B.Eng and Ph.D. degree from Tsinghua University, China, in 2016 and 2021 respectively. Her Ph.D advisor is <a href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm">Prof. Yong-Jin Liu</a>, and the lab director is <a href="https://cg.cs.tsinghua.edu.cn/#people.htm#shimin.htm">Prof. Shi-Min Hu</a>. She also closely collaborates with <a href="http://users.cs.cf.ac.uk/Yukun.Lai/">Prof. Yu-Kun Lai</a>, <a href="http://users.cs.cf.ac.uk/Paul.Rosin/">Prof. Paul L. Rosin</a> and <a href="https://personal.ntu.edu.sg/yhe/">Prof. Ying He</a>. Her research interests include computer vision, computer graphics and machine intelligence.
</p>

<p>
	[ <a href="#interests"><u>Research Interests</u></a>
	| <a href="#openings"><u>Openings</u></a>
	| <a href="#publications"><u>Publications</u></a>
	| <a href="#honors"><u>Honors</u></a>
	| <a href="#education"><u>Education</u></a>
	| <a href="#working"><u>Working</u></a>
	| <a href="#course"><u>Teaching</u></a>
	| <a href="#activities"><u>Activities</u></a>
	] <br>
</p>

<hr>

<h2><font color="red">News</font></h2>
<ul style="font-size: 11pt;">
<li>[2024.02.27] 4 papers accepted by CVPR 2024.</li>
<li>[2023.12.14] 1 paper accepted by TVCG.</li>
<li>[2023.12.09] 2 papers accepted by AAAI 2024.</li>
<li>[2023.08.04] 1 paper conditionally accepted by SIGGRAPH Asia 2023.</li>
<li>[2023.07.26] 2 papers accepted by ACM MM 2023.</li>
<li>[2023.07.14] 5 papers accepted by ICCV 2023.</li>
<li>[2023.05.18] 1 paper accepted by TVCG.</li>
<li>[2023.04.20] 1 paper accepted by IJCAI 2023.</li>
<li>[2023.02.28] 3 papers accepted by CVPR 2023.</li>
<li>[2022.09.13] 1 paper accepted by TMM.</li>
<li>[2022.07.04] 2 papers accepted by ECCV 2022.</li>
<li>[2022.06.30] 2 papers accepted by ACM MM 2022.</li>
<li>[2022.04.26] 1 paper accepted by SIGGRAPH 2022.</li>
<li>[2022.04.21] 1 paper accepted by IJCAI 2022.</li>
<li>[2022.03.02] 2 papers accepted by CVPR 2022.</li>
<li>[2022.01.27] 1 paper accepted by TPAMI.</li>
<li>[2022.01.08] 1 paper accepted by TMM.</li>
<li>[2021.12.01] 1 paper accepted by AAAI 2022.</li>
<li>[2021.11.06] 1 paper accepted by TVCG.</li>
<li>[2021.07.03] I joined SJTU as an assistant professor.</li>
<li>[2021.05.18] I passed PhD thesis defense.</li>
<li>[2021.03.15] 1 paper accepted by TVCG.</li>
<li>[2020.04.08] 1 paper accepted by TPAMI.</li>
<li>[2020.03.06] 1 paper accepted by TPAMI.</li>
<li>[2020.02.24] 1 paper accepted by CVPR 2020.</li>
</ul>

<h2><a name="interests" id="interests"></a>Research Interests &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<p>
	Computer Vision, Computer Graphics.<br>
</p>
<p>
	Some specific research interests:
	<ul>
	<li> Image/video/3D generation </li>
	<li> Artistic portrait stylization </li>
	<li> Rendering quality enhancement </li>
	<li> 3D geometry processing</li>
	</ul>
</p>

<h2><a name="openings" id="openings"></a>Openings / Internship &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<p>
	I am looking for self-motivated PhD, master and undergraduate students to join my research group! If you are interested in computer vision, computer graphics and want to join us, please send me your CV via email. For more info about internship at our group, please refer to <a href="https://dmcv.sjtu.edu.cn/data/internship.pdf">this link</a>.<br>
</p>
<p>
	团队招收博士生，硕士生和对科研感兴趣的本科生！如果你对计算机视觉、计算机图形学感兴趣，希望加入我们团队，欢迎与我邮件联系（邮件请附上个人简历）
</p>

<h2>
	<a name="publications" id="publications"></a>Selected Publications &nbsp;  
	<small>
	<a href="#pub2024"><u>2024</u></a>&nbsp;
	<a href="#pub2023"><u>2023</u></a>&nbsp;
	<a href="#pub2022"><u>2022</u></a>&nbsp;
	<a href="#pub2021"><u>2021</u></a>&nbsp;
	<a href="#pub2020"><u>2020</u></a>&nbsp;
	<a href="#pub2019"><u>2019</u></a>&nbsp;
	<a href="#pub2018"><u>2018</u></a>&nbsp;
	<a href="#pub2016"><u>2016</u></a>&nbsp;
	<a href="#top" class="txt"><u>Top</u></a>
    </small> <br>
</h2>
<table width="100%" border="0" align="center" cellpadding="5" cellspacing="10" style="font-size: 10pt;">
	<tr> 
	(* corresponding author)<br>
	<small>Summary: IEEE TPAMI (3) + ACM TOG (2) + SIGGRAPH (Asia) Conference (2)+ CVPR/ICCV (14) + IEEE TVCG (4) + AAAI/IJCAI/ACM MM (9)</small>
	</tr>
	<tr> <td><a name="pub2023"></a>2023</td> </tr>
	<tr>
		<td><img src="images/CVPR2023-BAID.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Towards Artistic Image Aesthetics Assessment: a Large-scale Dataset and a New Method <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Towards_Artistic_Image_Aesthetics_Assessment_A_Large-Scale_Dataset_and_a_CVPR_2023_paper.pdf">[paper]</a>
         <a href="https://github.com/Dreemurr-T/BAID">[dataset + code]</a><br>
         <strong>Ran Yi*</strong>, Haoyuan Tian, Zhihao Gu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2023-Few-shot-Diffusion.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Phasic Content Fusing Diffusion Model with Directional Distribution Consistency for Few-Shot Model Adaption
		<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.html">[paper]</a>
        <a href="https://github.com/sjtuplayer/few-shot-diffusion">[code]</a><br>
        Teng Hu, Jiangning Zhang, Liang Liu, <strong>Ran Yi*</strong>, Siqi Kou, Haokun Zhu, Xu Chen, Yabiao Wang, Chengjie Wang, Lizhuang Ma<br>
        <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ACM-MM-2023-Neural-Painting.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Stroke-based Neural Painting and Stylization with Dynamically Predicted Painting Region 
		<a href="https://dl.acm.org/doi/10.1145/3581783.3611766">[paper]</a>
		<a href="https://github.com/sjtuplayer/Compositional_Neural_Painter">[code]</a>
		<br>
        Teng Hu, <strong>Ran Yi*</strong>, Haokun Zhu, Liang Liu, Jinlong Peng, Yabiao Wang, Chengjie Wang, and Lizhuang Ma<br>
        <i>ACM International Conference on Multimedia <strong>(ACM MM)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/AAAI-2024-AnomalyDiffusion.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model 
		<a href="https://arxiv.org/abs/2312.05767">[arxiv]</a>
		<a href="https://sjtuplayer.github.io/anomalydiffusion-page/">[project]</a>
		<a href="https://github.com/sjtuplayer/anomalydiffusion">[code]</a>
		<br>
        Teng Hu, Jiangning Zhang, <strong>Ran Yi*</strong>, Yuzhen Du, Xu Chen, Liang Liu, Yabiao Wang, Chengjie Wang<br>
        <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2024 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR2023-M3DM.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Multimodal Industrial Anomaly Detection via Hybrid Fusion <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Multimodal_Industrial_Anomaly_Detection_via_Hybrid_Fusion_CVPR_2023_paper.pdf">[paper]</a>
         <a href="https://github.com/nomewang/M3DM">[code]</a><br>
         Yue Wang, Jinlong Peng, Jiangning Zhang, <strong>Ran Yi*</strong>, Yabiao Wang, Chengjie Wang<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ACM-MM-2023-Facial-Representation.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Toward High Quality Facial Representation Learning 
		<a href="https://dl.acm.org/doi/10.1145/3581783.3611999">[paper]</a>
        <a href="https://github.com/nomewang/MCF">[code]</a>
        <br>
        Yue Wang, Jinlong Peng, Jiangning Zhang, <strong>Ran Yi*</strong>, Liang Liu, Yabiao Wang, Chengjie Wang<br>
        <i>ACM International Conference on Multimedia <strong>(ACM MM)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2023-Open-World-DeepFake.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Contrastive Pseudo Learning for Open-World DeepFake Attribution 
		<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.html">[paper]</a>
        <a href="https://github.com/TencentYoutuResearch/OpenWorld-DeepFakeAttribution">[code]</a><br>
        Zhimin Sun, Shen Chen, Taiping Yao, Bangjie Yin, <strong>Ran Yi*</strong>, Shouhong Ding*, Lizhuang Ma<br>
        <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TVCG-2023-3D-Caption.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Complete 3D Relationships Extraction Modality Alignment Network for 3D Dense Captioning 
         <a href="https://ieeexplore.ieee.org/document/10132066">[paper]</a> 
         <br>
         Aihua Mao*, Zhi Yang, Wanxin Chen, <strong>Ran Yi*</strong>, Yong-Jin Liu<br>
         <i>IEEE Transactions on Visualization and Computer Graphics <strong>(TVCG)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/AAAI-2024-CPABMM.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
        Continuous Piecewise-Affine Based Motion Model for Image Animation 
        <a href="https://arxiv.org/abs/2401.09146">[arxiv]</a>
		<a href="https://github.com/DevilPG/AAAI2024-CPABMM">[code]</a>
        <br>
        Hexiang Wang, Fengqi Liu, Qianyu Zhou, <strong>Ran Yi*</strong>, Xin Tan, Lizhuang Ma*<br>
        <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2024 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/IJCAI2023-RFENet.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
        RFENet: Towards Reciprocal Feature Evolution for Glass Segmentation 
        <a href="https://www.ijcai.org/proceedings/2023/80">[paper]</a>
        <a href="https://github.com/VankouF/RFENet">[code]</a><br>
        Ke Fan, Changan Wang, Yabiao Wang, Chengjie Wang, <strong>Ran Yi*</strong>, Lizhuang Ma*<br>
        <i>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TVCG-2024-Sharp-Feature.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         MSL-Net: Sharp Feature Detection Network for 3D Point Clouds
         <a href="https://ieeexplore.ieee.org/document/10373950/">[paper]</a>
         <br>
         Xianhe Jiao, Chenlei Lv, <strong>Ran Yi</strong>, Junli Zhao, Zhenkuan Pan, Zhongke Wu, Yong-Jin Liu<br>
         <i>IEEE Transactions on Visualization and Computer Graphics <strong>(TVCG)</strong></i>, 2024 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR2023-IADG.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Instance-Aware Domain Generalization for Face Anti-Spoofing <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf">[paper]</a>
         <a href="https://github.com/qianyuzqy/IADG">[code]</a><br>
         Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, <strong>Ran Yi</strong>, Shouhong Ding, Lizhuang Ma<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2023-Make-It-3D.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
        Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior 
        <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.html">[paper]</a>
        <a href="https://make-it-3d.github.io/">[project]</a>
        <a href="https://github.com/junshutang/Make-It-3D">[code]</a><br>
        Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, <strong>Ran Yi</strong>, Lizhuang Ma, Dong Chen<br>
        <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2023-LiDAR-Camera.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment 
		<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.html">[paper]</a>
		<a href="https://github.com/zhangzw12319/lcps">[code]</a>
		<br>
        Zhiwei Zhang, Qian Yu, Zhizhong Zhang, <strong>Ran Yi</strong>, Yuan Xie, Lizhuang Ma<br>
        <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2023-MemKD-Anomaly-Detection.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Remembering Normality: Memory-guided Knowledge Distillation for Unsupervised Anomaly Detection 
		<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.html">[paper]</a>
		<br>
        Zhihao Gu, Liang Liu, Xu Chen, <strong>Ran Yi</strong>, Jiangning Zhang, Yabiao Wang, Chengjie Wang, Annan Shu, Guannan Jiang, Lizhuang Ma<br>
        <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2023 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/SIGGRAPH_Asia_2023_RT-Octree.jpeg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         RT-Octree: Accelerate PlenOctree Rendering with Batched Regular Tracking and Neural Denoising for Real-time Neural Radiance Fields <a href="https://dl.acm.org/doi/10.1145/3610548.3618214">[paper]</a>
         <a href="https://rt-octree.github.io/">[project]</a>
         <a href="https://github.com/LumiOwO/RT-Octree">[code]</a>
         <br>
         Zixi Shu, <strong>Ran Yi*</strong>, Yuqi Meng, Yutong Wu, Lizhuang Ma<br>
         <i>ACM SIGGRAPH Asia 2023 Conference Proceedings <strong>(SIGGRAPH Asia)</strong></i>, 2023 <br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/Arxiv-2023-T3Bench.png" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
        T3Bench: Benchmarking Current Progress in Text-to-3D Generation 
        <a href="https://arxiv.org/abs/2310.02977">[arxiv]</a>
        <a href="https://t3bench.com/">[project]</a>
        <a href="https://github.com/THU-LYJ-Lab/T3Bench">[code]</a><br>
        Yuze He, Yushi Bai, Matthieu Lin, Wang Zhao, Yubin Hu, Jenny Sheng, <strong>Ran Yi</strong>, Juanzi Li, Yong-Jin Liu<br>
        <i><strong>Arxiv</strong></i>, 2023 <br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICASSP-2023-EMCLR.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         EMCLR: Expectation Maximization Contrastive Learning Representations 
         <a href="https://ieeexplore.ieee.org/abstract/document/10094790">[paper]</a>
         <br>
         Meng Liu, <strong>Ran Yi*</strong>, Lizhuang Ma*<br>
         <i>IEEE International Conference on Acoustics, Speech and Signal Processing <strong>(ICASSP)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	

	<tr> <td><a name="pub2022"></a>2022</td> </tr>
	<tr>
		<td><img src="images/SIG2022.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Animating Portrait Line Drawings from a Single Face Photo and a Speech Signal <a href="https://dl.acm.org/doi/10.1145/3528233.3530720">[paper]</a>
         <a href="https://github.com/AnimatePortrait/AnimatePortrait">[code]</a>
         <a href="./images/SIG2022_demo.mp4">[demo video]</a><br>
         <strong>Ran Yi</strong>, Zipeng Ye, Ruoyu Fan, Yezhi Shu, Yong-Jin Liu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>ACM SIGGRAPH 2022 Conference Proceedings <strong>(SIGGRAPH)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TPAMI2022-QMUPD.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data <a href="https://ieeexplore.ieee.org/document/9699090">[paper]</a>
         <a href="https://github.com/yiranran/QMUPD">[code]</a><br>
         <strong>Ran Yi</strong>, Yong-Jin Liu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TMM2022-Personalized-Head-Movement.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Predicting Personalized Head Movement From Short Video and Speech Signal <a href="https://ieeexplore.ieee.org/document/9894719">[paper]</a>
         <a href="https://github.com/yiranran/Predict-Personalized-Head-Movement-TMM">[code]</a>
         <a href="https://ieeexplore.ieee.org/document/9894719/media#media">[demo video]</a>
         <br>
         <strong>Ran Yi</strong>, Zipeng Ye, Zhiyao Sun, Juyong Zhang, Guoxin Zhang, Pengfei Wan, Hujun Bao, Yong-Jin Liu<br>
         <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TMM2022-Dynamic-Convolution.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Audio-Driven Talking Face Video Generation with Dynamic Convolution Kernels <a href="https://ieeexplore.ieee.org/document/9681173">[paper]</a>
         <a href="https://ieeexplore.ieee.org/ielx7/6046/4456689/9681173/supp1-3142387.mp4?arnumber=9681173">[demo video]</a><br>
         Zipeng Ye, Mengfei Xia, <strong>Ran Yi*</strong>, Juyong Zhang, Yu-Kun Lai, Xuwei Huang, Guoxin Zhang, Yong-Jin Liu*<br>
         <i>IEEE Transactions on Multimedia <strong>(TMM)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR2022-LAKeNet.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         LAKe-Net: Topology-Aware Point Cloud Completion by Localizing Aligned Keypoints <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.html">[paper]</a>
         <a href="https://github.com/junshutang/LAKe-Net">[code]</a><br>
         Junshu Tang, Zhijun Gong, <strong>Ran Yi*</strong>, Yuan Xie, Lizhuang Ma*<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/MM2022-ScatterNet.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         ScatterNet: Point Cloud Learning via Scatters 
         <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548354">[paper]</a><br>
         Qi Liu, Nianjuan Jiang, Jiangbo Lu, Mingang Chen, <strong>Ran Yi*</strong>, Lizhuang Ma*<br>
         <i>ACM International Conference on Multimedia <strong>(ACM MM)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR2022-ISDNet.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-high Resolution Segmentation 
         <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.html">[paper]</a>
         <a href="https://github.com/cedricgsh/isdnet">[code]</a>
         <br>
         Shaohua Guo, Liang Liu, Zhenye Gan, Yabiao Wang, Wuhao Zhang, Chengjie Wang, Guannan Jiang, Wei Zhang, <strong>Ran Yi*</strong>, Lizhuang Ma*, Ke Xu<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/AAAI2022-face-forgery.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Exploiting Fine-grained Face Forgery Clues via Progressive Enhancement Learning <a href="https://ojs.aaai.org/index.php/AAAI/article/view/19954">[paper]</a><br>
         Qiqi Gu, Shen Chen, Taiping Yao, Yang Chen, Shouhong Ding*, <strong>Ran Yi*</strong><br>
         <i>AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/MM2022-AMEL.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Adaptive Mixture of Experts Learning for Generalizable Face Anti-Spoofing <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547769">[paper]</a><br>
         Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, <strong>Ran Yi</strong>, Shouhong Ding, Lizhuang Ma<br>
         <i>ACM International Conference on Multimedia <strong>(ACM MM)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/IJCAI2022-deepfake-detection.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Region-Aware Temporal Inconsistency Learning for DeepFake Video Detection <a href="https://www.ijcai.org/proceedings/2022/129">[paper]</a><br>
         Zhihao Gu, Taiping Yao, Yang Chen, <strong>Ran Yi</strong>, Shouhong Ding, Lizhuang Ma<br>
         <i>International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong></i>, 2022 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ECCV2022-GDA.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Generative Domain Adaptation for Face Anti-Spoofing <a href="https://link.springer.com/chapter/10.1007/978-3-031-20086-1_30">[paper]</a><br>
         Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, <strong>Ran Yi</strong>, Kekai Sheng, Shouhong Ding, Lizhuang Ma<br>
         <i>European Conference on Computer Vision <strong>(ECCV)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ECCV2022-OptDE.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Optimization over Disentangled Encoding: Unsupervised Cross-Domain Point Cloud Completion via Occlusion Factor Manipulation 
         <a href="https://link.springer.com/chapter/10.1007/978-3-031-20086-1_30">[paper]</a>
         <a href="https://github.com/azuki-miho/OptDE">[code]</a><br>
         Jingyu Gong, Fengqi Liu, Jiachen Xu, Min Wang, Xin Tan, Zhizhong Zhang, <strong>Ran Yi</strong>, Haichuan Song, Yuan Xie, Lizhuang Ma<br>
         <i>European Conference on Computer Vision <strong>(ECCV)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICME2022-RCCR.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization 
         <a href="https://ieeexplore.ieee.org/abstract/document/9859793">[paper]</a>
         <a href="https://github.com/qianyuzqy/RCCR">[code]</a><br>
         Qianyu Zhou, Chuyun Zhuang, <strong>Ran Yi</strong>, Xuequan Lu, Lizhuang Ma.<br>
         <i>IEEE International Conference on Multimedia and Expo <strong>(ICME)</strong></i>, 2022 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	
	<tr> <td><a name="pub2021"></a>2021</td> </tr>
	<tr>
		<td><img src="images/TVCG-2021-multi-cartoon.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         GAN-based Multi-Style Photo Cartoonization 
         <a href="https://ieeexplore.ieee.org/document/9382902">[paper]</a>
         <a href="https://github.com/syz825211943/Multi-Style-Photo-Cartoonization">[code]</a>
         <br>
         Yezhi Shu#, <strong>Ran Yi# (equal contribution)</strong>, Mengfei Xia, Zipeng Ye, Wang Zhao, Yang Chen, Yu-Kun Lai, Yong-Jin Liu<br>
         <i>IEEE Transactions on Visualization and Computer Graphics <strong>(TVCG)</strong></i>, 2021 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/3D-Caricature.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         3D-CariGAN: An End-to-End Solution to 3D Caricature Generation from Normal Face Photos <a href="https://ieeexplore.ieee.org/document/9609545">[paper]</a>
         <a href="https://github.com/qq775193759/3D-CariGAN">[code]</a><br>
         Zipeng Ye, Mengfei Xia, Yanan Sun, <strong>Ran Yi*</strong>, Minjing Yu*, Juyong Zhang, Yu-Kun Lai, Yong-Jin Liu*<br>
         <i>IEEE Transactions on Visualization and Computer Graphics <strong>(TVCG)</strong></i>, 2021 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	
	<tr> <td><a name="pub2020"></a>2020</td> </tr>
	<tr>
		<td><img src="images/TPAMI-2020-portrait.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Line Drawings for Face Portraits from Photos using Global and Local Structure based GANs <a href="https://ieeexplore.ieee.org/document/9069416/">[paper]</a>
         <a href="https://github.com/yiranran/APDrawingGAN2">[code]</a> 
         <a href="https://github.com/yiranran/APDrawingGAN2-Jittor">[code (Jittor)]</a>
         <br>
         <strong>Ran Yi</strong>, Mengfei Xia, Yong-Jin Liu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2020 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR-2020-Unpaired.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yi_Unpaired_Portrait_Drawing_Generation_via_Asymmetric_Cycle_Mapping_CVPR_2020_paper.pdf">[paper]</a>
         <a href="https://github.com/yiranran/Unpaired-Portrait-Drawing">[code]</a> 
         <a href="https://github.com/yiranran/Unpaired-Portrait-Drawing-Jittor">[code (Jittor)]</a>
         <br>
         <strong>Ran Yi</strong>, Yong-Jin Liu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2020 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/TPAMI-2020-supervoxel.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
		Feature-Aware Uniform Tessellations on Video Manifold for Content-Sensitive Supervoxels <a href="https://ieeexplore.ieee.org/document/9031395">[paper]</a>
        <a href="https://github.com/yiranran/FCSS">[code]</a>
        <a href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/demo_fcss.wmv">[demo video]</a> <br>
		<strong>Ran Yi</strong>, Zipeng Ye, Wang Zhao, Minjing Yu, Yu-Kun Lai, Yong-Jin Liu<br>
		<i>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong></i>, 2020 <font color="red">[CCF A]</font><br>
        </div>
        </td>
	</tr>
	<tr>
		<td><img src="images/CAD-Dirichlet.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Dirichlet energy of Delaunay meshes and intrinsic Delaunay triangulations <a href="https://www.sciencedirect.com/science/article/pii/S0010448520300440">[paper]</a> <br>
         Zipeng Ye, <strong>Ran Yi</strong>, Wenyong Gong, Ying He, Yong-Jin Liu<br>
         <i>Computer-Aided Design <strong>(CAD)</strong></i>, 2020 <font color="green">[CCF B]</font><br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/Audio-Driven-Talking-Head.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
			Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose <a href="https://arxiv.org/abs/2002.10137">[paper]</a>
			<a href="https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose">[code]</a>
			<a href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/video_arxiv.mp4">[demo video]</a> 
			<br>
			<strong>Ran Yi</strong>, Zipeng Ye, Juyong Zhang, Hujun Bao, Yong-Jin Liu<br>
			<i><strong>Arxiv</strong></i>, 2020 <br>
     	</div>
		</td>
	</tr>

	<tr> <td><a name="pub2019"></a>2019</td> </tr>
	<tr>
		<td><img src="images/CVPR-2019-APDrawingGAN.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.html">[paper]</a>
         <a href="https://github.com/yiranran/APDrawingGAN">[code]</a>
         <a href="http://cg.cs.tsinghua.edu.cn/people/~Yongjin/APDrawingDB.zip">[dataset]</a>
         <a href="https://github.com/yiranran/APDrawingGAN-Jittor">[code (Jittor)]</a>
         <br>
         <strong>Ran Yi</strong>, Yong-Jin Liu, Yu-Kun Lai, Paul L. Rosin<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2019 (<font color="purple">oral</font>) <font color="red">[CCF A]</font><br>
         <br>
     	</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/ICCV-2019-qdcss2.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Fast Computation of Content-Sensitive Superpixels and Supervoxels using q-distances 
         <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Ye_Fast_Computation_of_Content-Sensitive_Superpixels_and_Supervoxels_Using_Q-Distances_ICCV_2019_paper.pdf">[paper]</a> 
         <a href="https://github.com/qq775193759/qdcss_open_source">[code]</a>
         <br>
         Zipeng Ye#, <strong>Ran Yi# (equal contribution)</strong>, Minjing Yu, Yong-Jin Liu, Ying He<br>
         <i>IEEE International Conference on Computer Vision <strong>(ICCV)</strong></i>, 2019 <font color="red">[CCF A]</font><br>
     	</div>
		</td>
	</tr>
	
	<tr> <td><a name="pub2018"></a>2018</td> </tr>
	<tr>
		<td><img src="images/SIGASIA-2018-Delaunay.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Delaunay Mesh Simplification with Differential Evolution <a href="https://doi.org/10.1145/3272127.3275068">[paper]</a>
         <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3272127.3275068&file=a263-yi.mp4">[demo video]</a> <br>
         <strong>Ran Yi</strong>, Yong-Jin Liu, Ying He<br>
         <i>ACM Transactions on Graphics <strong>(SIGGRAPH ASIA)</strong></i>, 2018 <font color="red">[CCF A]</font><br>
		</div>
		</td>
	</tr>
	<tr>
		<td><img src="images/CVPR-2018-supervoxel.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Content-Sensitive Supervoxels via Uniform Tessellations on Video Manifolds <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Yi_Content-Sensitive_Supervoxels_via_CVPR_2018_paper.pdf">[paper]</a><br>
         <strong>Ran Yi</strong>, Yong-Jin Liu, Yu-Kun Lai<br>
         <i>IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong></i>, 2018 <font color="red">[CCF A]</font><br>
         <br>
		</div>
		</td>
	</tr>
	<tr> <td><a name="pub2016"></a>2016</td> </tr>
	<tr>
		<td><img src="images/SIGASIA-2016-MDE.jpg" width="75" height="75"></td>
		<td>
		<div style="margin-left: 20px">
         Manifold Differential Evolution (MDE): A Global Optimization Method for Geodesic Centroidal Voronoi Tessellations on Meshes <a href="https://dl.acm.org/doi/10.1145/2980179.2982424">[paper]</a>
         <a href="http://cg.cs.tsinghua.edu.cn/people/~Yongjin/MDE-demo.zip">[demo video]</a> <br>
         Yong-Jin Liu, Chun-Xu Xu, <strong>Ran Yi</strong>, Dian Fan, Ying He<br>
         <i>ACM Transactions on Graphics <strong>(SIGGRAPH ASIA)</strong></i>, 2016 <font color="red">[CCF A]</font><br>
		</div>
		</td>
	</tr>
</table>

<h2><a name="honors" id="honors"></a>Honors &amp; Awards  &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<ul style="font-size: 11pt;">
	<li> <strong>2022年CCF-腾讯犀牛鸟基金卓越项目</strong> (The CCF-Tencent RhinoBird Fund Outstanding Project), 2023.10 </li>
	<li> <strong>2023年ACM SIGAI China新星奖</strong> (ACM SIGAI China Rising Star Award), 2023.10 </li>
	<li> <strong>CAD/Graphics 2023 Best Paper Honorable Mention Award</strong>, 2023.8 </li>
	<li> <strong>2022年吴文俊人工智能优秀博士学位论文奖</strong> (Wu Wenjun Artificial Intelligence Excellent Doctoral Dissertation), 2023.03 </li>
	<li> 入选<strong>第八届中国科协青年人才托举工程</strong> (Young Elite Scientists Sponsorship Program by CAST), 2023.02 </li>
	<li> <strong>2022年中国图象图形学学会高等教育教学成果奖一等奖</strong>，排名5 (The First Prize of Higher Education Teaching Achievement Award of China Society of Image and Graphics in 2022), 2022.11 </li>
	<li> <strong>2021年北京市科学技术进步奖二等奖</strong>，排名9 (The Second Class of Beijing Science and Technology Progress Award 2021), 2022.11 </li>
	<li> <strong>2022年瑞士Chorafas青年研究奖</strong> (The Dimitris N. Chorafas Foundation Young Researcher Award), 2022.7 </li>
	<li> <strong>2021年中国图象图形学学会石青云女科学家奖（青英组）</strong> (China Society of Image and Graphics Shi QingYun Female Scientist Award (QingYing Group)), 2021.12 </li>
	<li> <strong>IGTA Paper Competition First Prize</strong>, 2021.08 </li>
	<li> <strong>Beijing Outstanding Graduates</strong>, 2021.07 <br>
	</li>
	<li> <strong>Excellent Doctoral Dissertation of Beijing Society of Image and Graphics (BSIG)</strong>, 2021.06 </li>
	<li> <strong>Excellent Doctoral Dissertation of Tsinghua University</strong>, 2021.06 </li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2020.12</li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2019.12</li>
	<li> <strong>CCF-CV 学术新锐奖</strong> (CCF-CV Academic Emerging Award), CCF-CV, 2019.11</li>
	<li> <strong>Microsoft Research Asia Fellowship Nomination Award</strong>, Microsoft, 2019.11</li>
	<li> <strong>China National Scholarship</strong>, Tsinghua University, 2018.11</li>
	<li> <strong>CCF-CV 学术新锐奖提名</strong>, CCF-CV, 2018.10 </li>
	<li> <strong>Beijing Outstanding Graduates</strong>, 2016.06 <br>
	</li>
	<li> <strong>Excellent Graduates of Tsinghua University</strong>, Tsinghua University, 2016.07 <br>
	</li>
	<li> <strong>Excellent Academic Performance Single Scholarship</strong>, Tsinghua University, 2015.10 </li>
	<li> <strong>Excellent Academic Performance Single Scholarship</strong>, Tsinghua University, 2014.10 </li>

</ul>

<h2><a name="education" id="education"></a>Education &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<ul>
<li><p>2012/08&ndash;2016/07: Tsinghua University, EE Dept, Bachelor</p></li>
<li><p>2016/09&ndash;2021/06: Tsinghua University, CS Dept, PhD</p>
	<p>Supervisor: <a href="https://cg.cs.tsinghua.edu.cn/people/~Yongjin/Yongjin.htm"><u>Prof. Yong-Jin Liu</u></a><br></p>
	<p>Lab director: <a href="https://cg.cs.tsinghua.edu.cn/#people.htm#shimin.htm"><u>Prof. Shi-Min Hu</u></a><br></p>
</li>
</ul>

<h2><a name="working" id="working"></a>Working Experience &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<ul>
<li><p>2021/07&ndash;Present: Shanghai Jiao Tong University, <a href="https://www.cs.sjtu.edu.cn/">CSE Dept</a>, Assistant Professor</p>
</li>
</ul>

<h2><a name="course" id="course"></a>Courses&nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<ul>
<li><p>CS3327 <strong>"VR & AR"</strong>: Spring, Undergraduate Course, with <a href="https://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=81"><u>Prof. Sheng Bin</u></a> <a href="https://sjtuvrar.github.io/">[Course Webpage]</a> </p></li>
<li><p>CS7332 <strong>"Computer Graphics"</strong>: Spring, Graduate Course, with <a href="https://dmcv.sjtu.edu.cn/people/"><u>Prof. Lizhuang Ma</u></a></p></li>
<li><p>CS4316 <strong>"Intelligent Computer Graphics and Vision Applications"</strong>: Autumn, Undergraduate Course, with <a href="https://dmcv.sjtu.edu.cn/people/"><u>Prof. Lizhuang Ma</u></a></p></li>
</ul>

<h2><a name="activities" id="activities"></a>Activities &nbsp;   <small><a href="#top" class="txt"><u>Top</u></a></small></h2>
<ul>
<li>Reviewer for Journal: TPAMI, IJCV, TIP, TMM, TVCG, TCSVT, etc</li>
<li>Reviewer for Conference: CVPR, ICCV, SIGGRAPH, SIGGRAPH Asia, AAAI, NeurIPS, ICML, ICLR, VR, etc</li>
</ul>



</div></body></html>